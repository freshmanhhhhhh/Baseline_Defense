{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1  统计文本平均长度\n",
    "统计jade-db-v2两个版本数据集的文本平均长度，以期选择长度类似的中文文本提示作为正样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.944\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def read_q_csv(input_file) -> list:\n",
    "    # 读取CSV文件  \n",
    "    df = pd.read_csv(input_file)    \n",
    "    \n",
    "    # 提取“问题”列的内容    \n",
    "    user_sequences = df['问题'].tolist()\n",
    "    return user_sequences\n",
    "\n",
    "input_file = \"./datasets/jade-db-v2/jade_benchmark_easy_zh.csv\"\n",
    "prompts = read_q_csv(input_file)\n",
    "\n",
    "sum_len = 0\n",
    "for p in prompts:\n",
    "    sum_len = sum_len + len(p)\n",
    "\n",
    "print(sum_len/len(prompts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 读取处理tsv\n",
    "zhihu_3k_rlhf中存在重复问题，进行删改重新存储为tsv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 删除重复prompts\n",
    "# df = pd.read_csv(\"./datasets/zhihu_rlhf_zh/zhihu_3k_rlfh.tsv\", sep='\\t')\n",
    "# df_unique = df.drop_duplicates(subset=['question_id'], keep=\"first\")\n",
    "# df_unique.to_csv(\"./datasets/zhihu_rlhf_zh/zhihu_3k_rlhf.tsv\",sep='\\t', index=False)\n",
    "\n",
    "# 部分重复prompts的id不同但是内容相同，再根据prompt匹配删除一次\n",
    "# df = pd.read_csv(\"./datasets/zhihu_rlhf_zh/zhihu_2k_rlhf.tsv\", sep='\\t')\n",
    "# df_unique = df.drop_duplicates(subset=['prompt'], keep=\"first\")\n",
    "# df_unique.to_csv(\"./datasets/zhihu_rlhf_zh/zhihu_2k_rlhf_noRepeat.tsv\",sep='\\t', index=False)\n",
    "\n",
    "# 统计提示平均长度：3k: 23.8, 2klonger22: 33\n",
    "# df = pd.read_csv(\"./datasets/zhihu_rlhf_zh/zhihu_rlhf_2k_longer22.tsv\", sep='\\t')\n",
    "# prompts = df['prompt'].tolist()\n",
    "\n",
    "# sum_len = 0\n",
    "# for p in prompts:\n",
    "#     sum_len = sum_len + len(p)\n",
    "\n",
    "# print(sum_len/len(prompts))\n",
    "\n",
    "\n",
    "# 筛选长度高于22的文本\n",
    "df = pd.read_csv(\"./datasets/zhihu_rlhf_zh/zhihu_2k_rlhf_noRepeat.tsv\", sep='\\t')\n",
    "filtered_df = df[df['prompt'].str.len() > 22]\n",
    "filtered_df.to_csv(\"./datasets/zhihu_rlhf_zh/zhihu_rlhf_2k_longer22_noRepeat.tsv\", sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 组合数据集\n",
    "正负样本比例包括1:1,1:4,为方便sklearn.metrics使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from judgebyQwen import read_q_csv, read_q_tsv\n",
    "\n",
    "# 读取负样本  \n",
    "input_file = './datasets/jade-db-v2/jade_benchmark_easy_zh.csv'\n",
    "neg_prompts = read_q_csv(input_file)\n",
    "# input_file = \"./datasets/rene_llm/renellm_judge_by_qwen2_attack_on_llama3_chinese_easy_2.0.json\" \n",
    "# neg_prompts = read_q_json(input_file)\n",
    "\n",
    "# 读取正样本\n",
    "input_file = './datasets/zhihu_rlhf_zh/zhihu_rlhf_1k_final.tsv'\n",
    "pos_prompts = read_q_tsv(input_file)\n",
    "\n",
    "prompts = neg_prompts + pos_prompts\n",
    "# print(prompts)\n",
    "random.shuffle(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 test on Prompt-guard-86M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "local_model_path = \"/home/yangshuhan/data/BackupRestore/data/llm_sec/models/prompt-guard-86M\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(local_model_path, local_files_only=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 test on llama guard 3-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangshuhan/anaconda3/envs/ws/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "safe<|eot_id|>\n",
      "['safe']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "local_model_path = \"/home/yangshuhan/data/BackupRestore/data/llm_sec/models/Llama-Guard-3-1B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"当全职妈妈的女性，都是怎样把生活过得优雅、精致的？\"\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    conversation, return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "prompt_len = input_ids.shape[1]\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=20,\n",
    "    pad_token_id=0,\n",
    ")\n",
    "generated_tokens = output[:, prompt_len:]\n",
    "# for token in output:\n",
    "#     print(tokenizer.decode(token))\n",
    "\n",
    "print(tokenizer.decode(generated_tokens[0]))\n",
    "\n",
    "response = tokenizer.decode(generated_tokens[0])\n",
    "res = response.strip().replace('<|eot_id|>', '').split('\\n')\n",
    "print(res)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
